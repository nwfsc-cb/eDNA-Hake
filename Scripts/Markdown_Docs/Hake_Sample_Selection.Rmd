---
title: "MURI hake sample selection"
author: "Ole Shelton"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

### Libraries
library(tidyverse)
library(knitr)
library(reshape2)
library(viridis)
library(ggmap)
library(maps)
library(mapdata)
library(sp)
library(gstat)
library(ggplot2)
library(sf)
#library(brms)
library(ggsci)
library(gridExtra)
library(cowplot)

```

# Initial Sample Selection (Feb. 2023)

## Samples from 2019

This is a short document identifying the samples identified for use in the first phase of the MURI project. These samples will be used in the initial application of the fish (MiFish) and marine mammal (D-LOOP) metabarcoding primers.  We decided to begin with samples near the surface (3m and 50m depth) and to shoot for 45 individual samples at each depth as an exploratory set.

```{r call_make_maps,message=FALSE,warning=FALSE,echo=FALSE}
ramon_loc <- read.csv("ramon_locations_Final_metadata.csv")

# pull in relevant data on samples and make maps
source("../_make_maps_hake_survey.R")

setwd(script.dir)
samp_vol_2019 <- read.csv("../Data/Hake eDNA 2019 qPCR results 2023-02-10 sample details.csv")
plate_id <- read.csv("../Data/qPCR/Hake eDNA 2019 qPCR results 2021-01-04 results.csv")

```

```{r muri_samples,message=FALSE,warning=FALSE,echo=FALSE}
# Make MURI samples.  Pull the data used in the final Hake model north of 46 N (WA state) from 2019
dat.station.max.depth <- Output.qpcr$dat.obs.bin %>% 
                            dplyr::select(station,depth_cat_factor,bottom.depth.consensus) %>%
                            mutate(depth.2 = as.numeric(as.character(depth_cat_factor))) %>%
                            group_by(station,bottom.depth.consensus) %>%
                            summarise(max.depth=max(bottom.depth.consensus,na.rm=T)) %>%
                            rename(CTD.cast = station)
                            
dat.muri <- dat.all %>% filter(source=="Hake") %>% left_join(.,dat.station.max.depth)

# pull sample numbers out of the big data frame
samps <- Output.qpcr$dat.obs.bin  %>% 
        filter(year==2019,
                    lat>46.2,
                    station %in% dat.muri$CTD.cast,
                    depth_cat %in% c(0,50)) %>%
        group_by(sample) %>% 
        mutate(inhibit_mean=mean(inhibit.val)) %>%
        distinct(year,sample,station,depth_cat,inhibit_mean,dilution) %>%
        arrange(station,depth_cat,sample) %>%
        left_join(.,dat.muri %>% dplyr::select(station=CTD.cast,Latitude,Longitude,bottom.depth.consensus))
                                        
#0 0Make a map of all the Hake stations in 2019
eDNA.map.hake.muri <-  base_map_trim_2022 +
  geom_point(data=dat.all %>% filter(source=="Hake",Year==2019),
             aes(x=Longitude,y=Latitude),shape=21,alpha=1,color="black") +
  # geom_point(data=dat.muri %>% filter(source=="Hake"),
  #            aes(x=Longitude,y=Latitude,color=bottom.depth.consensus),alpha=0.75) +
  # geom_point(data=dat.muri %>% filter(source=="Hake",max.depth>150),
  #            aes(x=Longitude,y=Latitude,color=max.depth),alpha=0.75,color="red") +
  coord_fixed(xlim=lon.lims.trim.proj.hake,ylim=lat.lims.trim.proj,ratio=1.2) +
  scale_color_viridis_c("Depth",option = "plasma", begin=0,end=0.7) +
  facet_wrap(~Year)
#eDNA.map.hake.muri

lat.lims.trim.proj.hake.wa <- c(46,48.4)
lon.lims.trim.proj.hake.wa <- c(lon.lims.trim.proj.hake[1],-123)

# Map of all WA stations in just 0 of 50m sampling depths.
eDNA.map.hake.muri.wa <-  base_map_trim_2022 +
  geom_point(data=samps,
             aes(x=Longitude,y=Latitude,color=as.factor(dilution)),alpha=0.5) +
  # geom_point(data=dat.muri %>% filter(source=="Hake",max.depth>150),
  #            aes(x=Longitude,y=Latitude,color=max.depth),alpha=0.75,color="red") +
  coord_fixed(xlim=lon.lims.trim.proj.hake.wa,ylim=lat.lims.trim.proj.hake.wa,ratio=1.2) +
  scale_color_viridis_d("Dilution",option = "plasma", begin=0,end=0.8) +
  facet_wrap(~depth_cat)
#eDNA.map.hake.muri.wa

N_station <- samps %>%ungroup() %>% distinct(station) %>% nrow()
N_station_0 <- samps %>%ungroup() %>% filter(depth_cat==0) %>% distinct(station) %>% nrow()
N_station_50 <- samps %>%ungroup() %>% filter(depth_cat==50) %>% distinct(station) %>% nrow()

```

We can present all of the sample locations for 2019, 2021 and 2022 (Fig. \ref{fig:all_samples}).

```{r fig_all_samples,message=FALSE,warning=FALSE,echo=FALSE,fig.cap="\\label{fig:all_samples} The locations of eDNA samples from three years of CTD collections from the hake acoustic-trawl survey.",out.height='6in'}
# present all hake samples and maps
print(eDNA.map.hake.mod)
```

Let's focus in on 2019 and focus in on sites north of 46.2 degrees latitude (off Washington state). There are `r N_station` stations in this area (with `r N_station_0` stations at the surface and `r N_station_50` at 50m; Fig. \ref{fig:map_0_50}). In total there are `r nrow(samps)` water samples from these sites at 0 and 50m. Many of the surface samples were diluted for use with the hake qPCR (Fig. \ref{fig:map_0_50}) with some stations having one of two replicates diluted and others having both replicates diluted. 

From this set of samples, we are looking to include 90-ish total samples for preliminary analysis or approximately 45 from each depth. This leaves some space on a single plate for controls. To trim down from `r nrow(samps)` individual water samples we will select a single water sample station which gets us to `r N_station_0 + N_station_50` samples, and leaves us to remove `r N_station_0 + N_station_50 - 90` samples to get to 90. Dropping one station from the middle of each line will get us there.


```{r fig.map_0_50 , echo=FALSE,fig.cap="\\label{fig:map_0_50} Samples from the 2019 hake cruise in Washington state waters at the surface and 50m depth. Colors indicate whether those samples were undiluted (1) or 1:5 diluted (0.2) in the qPCR included in hake analysis in 2019. Intermediate colors indicate that one of the replicate Niskin sample was diluted but the other was not.",out.width='100%'}
print(eDNA.map.hake.muri.wa)
```


```{r cull_muri_samples,message=FALSE,warning=FALSE,echo=FALSE}

samps <- samps %>% mutate(keep=1) %>%
              mutate(keep=case_when(station=="71-3"~ 0,
                                    station=="73-4"~ 0,
                                    station=="75-4"~ 0,
                                    station=="77-4"~ 0,
                                    station=="79-4"~ 0,
                                    station=="81-3"~ 0,
                                    station=="83-7"~ 0,
                                    station=="85-14"~ 0,
                                    TRUE~keep))
                                    
eDNA.map.hake.muri.wa.trim <-  base_map_trim_2022 +
  geom_point(data=samps,
             aes(x=Longitude,y=Latitude,color=as.factor(dilution)),alpha=0.5) +
  geom_point(data=samps %>%filter(keep==0),
             aes(x=Longitude,y=Latitude),color="red",alpha=0.5) +
  # geom_point(data=dat.muri %>% filter(source=="Hake",max.depth>150),
  #            aes(x=Longitude,y=Latitude,color=max.depth),alpha=0.75,color="red") +
  coord_fixed(xlim=lon.lims.trim.proj.hake.wa,ylim=lat.lims.trim.proj.hake.wa,ratio=1.2) +
  scale_color_viridis_d("Dilution",option = "plasma", begin=0,end=0.8) +
  facet_wrap(~depth_cat)

samps.trim <- samps %>% filter(keep==1)
```

```{r fig.map_0_50_trim , echo=FALSE,fig.cap="\\label{fig:map_0_50_trim} Samples from the 2019 hake cruise in Washington state waters at the surface and 50m depth. Colors indicate whether those samples were undiluted (1) or 1:5 diluted (0.2) in the qPCR included in hake analysis in 2019. Intermediate colors indicate that one of the replicate Niskin sample was diluted but the other was not. Red points identify stations proposed to be dropped",out.width='100%'}
print(eDNA.map.hake.muri.wa.trim)
```

The dropped lines are in the middle of each transect and most fall approximately along the shelf break, generally at either 300m or 500m bottom depth. Taking one sample from each station at each depth in Fig. \ref{fig:map_0_50_trim} results in `r samps.trim %>% ungroup() %>% distinct(station,depth_cat) %>% nrow(.)` samples (`r samps.trim %>% filter(depth_cat==0) %>% ungroup() %>% distinct(station,depth_cat) %>% nrow(.)` at the surface and `r samps.trim %>% filter(depth_cat==50) %>% ungroup() %>% distinct(station,depth_cat) %>% nrow(.)` at 50m). Here is a plot of the chosen stations by depth (Fig. \ref{fig:map_0_50_fin_ramon}). The only other person that has used substantial numbers of the 2019 samples is Ramon. I have outline in red the samples that I believe Ramon used in his metabarcoding work.  There is relatively limited overlap with the proposed set of stations and depths (Fig. \ref{fig:map_0_50_fin_ramon}). 

Among samples that were diluted, there should be three levels of dilution - 1:2, 1:5, and 1:10. Only 1:5 dilution data were used in the 2021 hake paper, but the other dilutions should be available. 

```{r muri_stations,message=FALSE,warning=FALSE,echo=FALSE}
eDNA.map.hake.muri.wa.trim2 <-  base_map_trim_2022 +
  geom_point(data=samps.trim,
             aes(x=Longitude,y=Latitude,color=as.factor(dilution)),alpha=0.5) +
  # geom_point(data=samps %>%filter(keep==0),
  #            aes(x=Longitude,y=Latitude),color="red",alpha=0.5) +
  # geom_point(data=dat.muri %>% filter(source=="Hake",max.depth>150),
  #            aes(x=Longitude,y=Latitude,color=max.depth),alpha=0.75,color="red") +
  coord_fixed(xlim=lon.lims.trim.proj.hake.wa,ylim=lat.lims.trim.proj.hake.wa,ratio=1.2) +
  scale_color_viridis_d("Dilution",option = "plasma", begin=0,end=0.8) +
  facet_wrap(~depth_cat)

```



```{r ramon_stations,message=FALSE,warning=FALSE,echo=FALSE}
ramon_loc_samp <- ramon_loc %>% dplyr::select(sample = eDNA.sample,
                                              station = Station) %>%
                      mutate(ramon_16S = 1)

samps.trim <- samps.trim %>% mutate(sample = as.character(sample)) %>%
                    left_join(., ramon_loc_samp %>% mutate(sample = as.character(sample))) %>%
                    mutate(ramon_16S = ifelse(is.na(ramon_16S),0,ramon_16S))
    

eDNA.map.hake.muri.wa.trim3 <-  eDNA.map.hake.muri.wa.trim2 +
                geom_point(data=samps.trim %>% filter(ramon_16S==1),
                        aes(x=Longitude,y=Latitude),color="red",shape=21,alpha=0.5) 

```

```{r fig.map_0_50_fin_ramon , echo=FALSE,fig.cap="\\label{fig:map_0_50_fin_ramon} Stations from the 2019 hake cruise in Washington state waters at the surface and 50m depth. Colors indicate whether those samples were undiluted (1) or 1:5 diluted (0.2) in the qPCR included in hake analysis in 2019. Intermediate colors indicate that one of the replicate Niskin sample was diluted but the other was not. Excluded stations not shown. Samples used by Ramon are outlined in red.",out.width='100%'}
print(eDNA.map.hake.muri.wa.trim3)
```

## Identifying samples

Now that we have the stations identified (Fig. \ref{fig:map_0_50_fin_ramon}) we need to identify the sample to use at each station. I have been using two criteria to identify these samples: 1) We will use samples that have a lot of sample remaining, so that multiple kinds of analyses can be run on a single sample; 2) We will prefer using undiluted to diluted samples from a given station because we are concerned about finding rare taxa.

This identification of samples that were used by Ramon is still tentative, but I plan on updating it as soon as I get the necessary info.  The list is presented in Table 1.  All of these samples putatitvely have more the 60$\mu L$ available, this does include the amount of sample used during Ramon's analysis.

Abi has informed me that there are 6 additional samples from 2022 that were collected during times in which  marine mammals were observed from the ship.  I would suggest including those samples during the metabarcoding run as well.


```{r remaining_samples,message=FALSE,warning=FALSE,echo=FALSE}
# Add Abi's estimate of remaining sample volume after accounting for only the qPCR processing.
samp_vol_2019 <- samp_vol_2019 %>% rename(sample=Tube..,station=CTD.cast) %>%
                          dplyr::select(sample,station,
                                        Vol.Used.TransferLosses,
                                        Vol.Used.Hake.qPCR,
                                        Vol.Used.Ramon,
                                        Volume)
samps.trim <- samps.trim %>% 
                    left_join(., samp_vol_2019)
                    
samps.trim <- samps.trim %>%
                rename(vol_remain_after_qPCR = Volume) %>%
                dplyr::select(sample, dilution,
                              station,
                              year,
                              depth_cat,
                              ramon_16S,
                              vol_remain_after_qPCR)

# Find the distinct sample-depth combinations
dist.samp.depth <- samps.trim %>% 
                      group_by(year,station,depth_cat) %>%
                      summarise(max.vol = max(vol_remain_after_qPCR),
                                min.vol = min(vol_remain_after_qPCR))

samps.filt <- left_join(dist.samp.depth,samps.trim) %>% 
                  filter(max.vol==vol_remain_after_qPCR | is.na(max.vol)) %>% # Only gets rid of a few samples.
                  ungroup() %>% mutate(sample = as.numeric(sample)) %>%
                  group_by(year,station,depth_cat) %>%
                  summarise(sample.keep = min(sample))

samps.keep <- samps.trim %>% filter(sample %in% samps.filt$sample.keep) %>%
                      #left_join(dist.samp.depth,.) %>% # add back in samples with NA for volumes
                      dplyr::select(year,sample,station,depth_cat,
                                    dilution,vol_remain =vol_remain_after_qPCR,
                                    ramon_16S)
```

Many of the surface samples were inhibited and diluted for use in the hake qPCR assay.  It is not clear whether the diluted or undiluted make more sense to use in the metabarcoding analysis, so I propose using a subset of samples in these pilot runs to explore the value of running diluted vs. undiluted DNA extract.  There are currently `r samps.keep %>% filter(dilution ==0.2) %>% distinct(sample,station) %>% nrow(.)` samples in our set that are diluted. I propose using the 12 northern-most of these samples to run at both undiluted and 1:5 dilution in our first round of metabarcoding.

```{r remaining_samples_2,message=FALSE,warning=FALSE,echo=FALSE}
dup <- samps.keep %>% filter(dilution ==0.2) %>% 
          distinct(sample,station) %>% arrange(desc(station))
dup <- dup[1:12,]
keepers <- samps.keep %>% filter(sample %in% c(dup$sample)) %>% mutate(dilution = 1)

samps.keep <- bind_rows(samps.keep,keepers) %>% arrange(year,station,sample,dilution)

write.csv(samps.keep,file="2019_hake_samples_MURI_pilot_2023-02.csv")

```


With these twelve samples included twice (once undiluted, once diluted 1:5), we are at `r samps.keep %>% nrow(.)` samples in total. Which is pretty close to the initial target of 90 samples. I print the samples of interest below, and in the csv ("2019_hake_samples_MURI_pilot_2023-02.csv"). Unfortunately, I do not have the location of the samples on the storage plates in this data frame, but they can be found in the file "Hake eDNA 2019 qPCR and results" in the "plates layout" tab in the google drive.


### Outstanding issues and notes

1. Need to add information about other analyses that has used these samples to date, if any.

\clearpage
```{r make_table_remaining_samples,message=FALSE,warning=FALSE,echo=FALSE}
kable(samps.keep,#label= "tab:samples",
       caption = "This is a table of samples that seem like samples to target for the pilot application of the D-LOOP and MiFish primers. This includes 12 samples used twice (once undiluted, once diluted 1:5).")
```

# Second Sample Selection (Oct. 2023)

