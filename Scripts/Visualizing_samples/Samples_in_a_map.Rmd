---
title: "Visualizing MiSeq output in a Map"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

After many, many attempts, I have a couple of successful MiSeq runs. Let's plot where are they from

```{r}
library(tidyverse)
library(here)
library (sf)


 library(raster)

named_pull <- function(x, values_from, names_from){
names.output<- pull(x, {{names_from}})
output <- pull(x, {{values_from}})
names(output)<- names.output
return(output)
}

```

# Get data and metadata

```{r}
metadata <- read_csv(here("Data", "eDNA.samples.with.lat.lon.csv"))

Run7 <- read_csv(here("Data/Pipeline_output/Run7/output_no_MaxEE/ASV_table.csv"))

Run8 <- read_csv(here("Data/Pipeline_output/Run8/output/ASV_table.csv"))

classified.hashes <- read_csv(here("Output/All.hash.classified.csv"))
```

Now get the map

```{r}


base_plot <- read_rds(here("Data/Hake_map.rds"))

```

# Join two datasets, merge by taxonomy
```{r}
classified.hashes %>% 
  rename (Hash = representative) %>% 
  unite (family, genus, species, col = "taxa", sep = "%") %>% 
  dplyr::select (Hash, taxa) -> tax.assignments

# Are there unclassifed hashes

bind_rows(Run7, Run8) %>% 
  distinct(Hash) %>% 
  anti_join(tax.assignments) # NOPE, we did our job

tax.assignments %>% 
   filter (taxa != "NA%NA%NA") %>%  # Remove ~500 Hashes for which we don't know even the family
  right_join(bind_rows(Run7, Run8, .id = "Run")) -> Combined.dataset

# Sanity check to see if the nas are way to many

Combined.dataset %>% 
  group_by(Hash) %>% 
  mutate (tot = sum(nReads)) %>% 
  group_by(is.na(taxa)) %>% 
  summarise (nhashes = n_distinct(Hash),
             nReads = sum(nReads),
             median = median(tot),
             max = max(tot))

  
#  There is a Hash that accounts for 260k reads that we don't have a taxonomy for it

Combined.dataset %>% 
  filter (is.na(taxa)) %>% 
  group_by(Hash) %>% 
  summarise (nsamples = n_distinct(Sample_name),
             nReads = sum( nReads)) %>% 
  arrange(desc(nReads)) %>% 
  filter (nsamples > 2 | nReads > 20000) -> Find.about  # Keep an interest on things that show up either more than twice, or more than 20k reads
  


Combined.dataset %>% 
  filter (!is.na(taxa)) %>% 
  group_by(Sample_name, Run, taxa) %>% 
  summarise(nReads = sum(nReads)) -> By.taxa.dataset


By.taxa.dataset %>% 
  filter (!str_detect(Sample_name, "Tilapia")) %>% 
  separate(Sample_name, into = c("eDNA.sample", "rep"), convert = T) %>% 
  left_join(metadata) -> By.taxa.dataset.metadata

By.taxa.dataset.metadata %>% 
  mutate (depth = str_replace(depth, "sfc", "0"),
          depth = as.numeric(depth)) %>% 
  group_by(Transect, position) %>% 
  mutate( Profile = case_when(depth == max(depth)~ "Bottom",
                              depth < (min(depth)+10) ~ "Surface",
                              TRUE                    ~ "MidWater")) -> By.taxa.dataset.metadata

By.taxa.dataset.metadata %>% 
  group_by(Transect, Profile, taxa) %>% 
  summarise (nrep = n(),
             nReads = sum(nReads)) -> all.summaries

all.summaries %>% 
  
  dplyr::select(-nReads, -Transect) %>% 
  group_by(taxa, Profile) %>%
  summarise(nrep  = sum(nrep)) %>% 
  pivot_wider(names_from = Profile, values_from = nrep, values_fill = list(nrep = 0)) 

```

```{r}
metadata %>% 
   mutate (depth = str_replace(depth, "sfc", "0"),
          depth = as.numeric(depth))

metadata %>% 
  summarise(across(c("lat", "lon"), .fns = list( Max = ~ round( max(.x, na.rm = T) + 1,0) ,
                                              Min = ~ round( min(.x, na.rm = T) - 1,0)))) %>% pivot_longer(cols = everything(),
                 names_to = "Corner",
                                                                                               values_to = "Coordinates") %>% named_pull(Coordinates, Corner)-> limits.for.map


# Bathymetry
b = marmap::getNOAA.bathy(lon1 = limits.for.map["lon_Max"],
                  lon2 = limits.for.map[ "lon_Min" ],
                  lat1 = limits.for.map["lat_Min"], 
                  lat2 = limits.for.map["lat_Max"], 
                  resolution = 1)

b <- fortify(b)

b %>% write_csv(here("Data","bathymetry.csv"))
sf::read_sf(here("Data","bathymetry.csv"),  options=c("X_POSSIBLE_NAMES=x","Y_POSSIBLE_NAMES=y")) -> b

sf::read_sf(here("Data", "eDNA.samples.with.lat.lon.csv"),
            options = c("X_POSSIBLE_NAMES=lon","Y_POSSIBLE_NAMES=lat")) -> metadata

metadata
```

Calculate the distance to bottom at each point
```{r}
metad.df <- as_tibble(metadata) %>% dplyr::select(x= lon, y=lat) %>% distinct() %>% rownames_to_column("FID")
extract(raster(b), metadata)
```


## Refocus

Make this 
